{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cr√©ation du Dataset en scrappant les infos depuis une liste d'url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marque</th>\n",
       "      <th>Parfum</th>\n",
       "      <th>Lien du Parfum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19318</td>\n",
       "      <td>19318</td>\n",
       "      <td>19318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>119</td>\n",
       "      <td>18643</td>\n",
       "      <td>19318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>The Dua Brand</td>\n",
       "      <td>Rose</td>\n",
       "      <td>https://www.fragrantica.com/perfume/Acqua-di-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1673</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Marque Parfum  \\\n",
       "count           19318  19318   \n",
       "unique            119  18643   \n",
       "top     The Dua Brand   Rose   \n",
       "freq             1673      8   \n",
       "\n",
       "                                           Lien du Parfum  \n",
       "count                                               19318  \n",
       "unique                                              19318  \n",
       "top     https://www.fragrantica.com/perfume/Acqua-di-P...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scraping_info_perfume as sip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "df = pd.read_csv('list_url_by_popular_designer.csv')\n",
    "\n",
    "# Choix de la lettre √† scraper\n",
    "lettre = 'T'\n",
    "df_a_scraper = df[df['Marque'].str.startswith(lettre)] \n",
    "df_a_scraper.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test pour voir le temps d'attente optimal √† scraper 50 parfums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'ex√©cution pour batch 1 : 44.2 secondes.\n",
      "Soit 8.8 secondes par URL.\n",
      "Temps d'ex√©cution pour batch 2 : 72.0 secondes.\n",
      "Soit 14.4 secondes par URL.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 49\n",
    "\n",
    "# Charger le dataset existant\n",
    "Fragrantica_dataset = pd.read_csv(\"Fragrantica_dataset.csv\")\n",
    "url_deja_scrape = set(Fragrantica_dataset['url'].tolist())\n",
    "\n",
    "# Filtrer les URLs d√©j√† scrap√©es\n",
    "df_a_scraper = df_a_scraper[~df_a_scraper['Lien du Parfum'].isin(url_deja_scrape)]\n",
    "\n",
    "# Initialiser les DataFrames pour les donn√©es scrap√©es\n",
    "scraped_data_1 = pd.DataFrame()\n",
    "scraped_data_2 = pd.DataFrame()\n",
    "\n",
    "# Fonction pour scraper un batch et mesurer le temps d'ex√©cution\n",
    "def scrape_batch(batch, batch_num):\n",
    "    liste_url = batch[\"Lien du Parfum\"].tolist()\n",
    "    start_time = time.time()\n",
    "    scraped_data = sip.scraping_multi_perfume_info(liste_url)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    scraped_data.to_csv(f\"scraped_data_{batch_num}.csv\", index=False)\n",
    "    return scraped_data, execution_time\n",
    "\n",
    "# Scraper le premier batch\n",
    "batch1 = df_a_scraper.iloc[0 : batch_size]\n",
    "scraped_data_1, execution_time_1 = scrape_batch(batch1, 1)\n",
    "print(f\"Temps d'ex√©cution pour batch 1 : {execution_time_1:.1f} secondes.\")\n",
    "print(f\"Soit {execution_time_1 / batch_size:.1f} secondes par URL.\")\n",
    "\n",
    "# Attendre avant de scraper le deuxi√®me batch\n",
    "time.sleep(180)\n",
    "\n",
    "# Scraper le deuxi√®me batch\n",
    "batch2 = df_a_scraper.iloc[batch_size : 2 * batch_size]\n",
    "scraped_data_2, execution_time_2 = scrape_batch(batch2, 2)\n",
    "print(f\"Temps d'ex√©cution pour batch 2 : {execution_time_2:.1f} secondes.\")\n",
    "print(f\"Soit {execution_time_2 / batch_size:.1f} secondes par URL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans Fragrantica_dataset : 578\n",
      "Nombre de lignes dans Fragrantica_dataset : 578\n",
      "Nombre de lignes dans Fragrantica_dataset : 588\n",
      "‚úÖ Les donn√©es ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Fragrantica_dataset = pd.read_csv(\"Fragrantica_dataset.csv\")\n",
    "print(f\"Nombre de lignes dans Fragrantica_dataset : {Fragrantica_dataset.shape[0]}\")\n",
    "scraped_data1 = pd.read_csv(f\"scraped_data_1.csv\")\n",
    "#afficher le nomre de ligne de chaque dataframe\n",
    "# Concat√©ner les deux DataFrames\n",
    "combined_data = pd.concat([Fragrantica_dataset, scraped_data1])\n",
    "combined_data.drop_duplicates(subset=['url'], inplace=True)\n",
    "combined_data.to_csv(\"Fragrantica_dataset.csv\", index=False)\n",
    "\n",
    "Fragrantica_dataset = pd.read_csv(\"Fragrantica_dataset.csv\")\n",
    "print(f\"Nombre de lignes dans Fragrantica_dataset : {Fragrantica_dataset.shape[0]}\")\n",
    "scraped_data2 = pd.read_csv(f\"scraped_data_2.csv\")\n",
    "combined_data = pd.concat([Fragrantica_dataset, scraped_data2])\n",
    "combined_data.drop_duplicates(subset=['url'], inplace=True)\n",
    "combined_data.to_csv(\"Fragrantica_dataset.csv\", index=False)\n",
    "\n",
    "\n",
    "Fragrantica_dataset = pd.read_csv(\"Fragrantica_dataset.csv\")\n",
    "print(f\"Nombre de lignes dans Fragrantica_dataset : {Fragrantica_dataset.shape[0]}\")\n",
    "print(f\"‚úÖ Les donn√©es ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le script qui scrape les infos par batch de 49 lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ TAILLE DES BATCHS = 49\n"
     ]
    }
   ],
   "source": [
    "batch_size = 49\n",
    "num_batches = len(df_a_scraper) // batch_size + (1 if len(df_a_scraper) % batch_size != 0 else 0)\n",
    "print(f\"üì¶ TAILLE DES BATCHS = {batch_size}\")\n",
    "\n",
    "time.sleep(3600)\n",
    "\n",
    "#1) Obtenir les URLs d√©j√† scrap√©es\n",
    "Fragrantica_dataset = pd.read_csv(\"Fragrantica_dataset.csv\")\n",
    "url_deja_scrape = set(Fragrantica_dataset['url'].tolist())  # Convertir en set pour acc√©l√©rer la recherche\n",
    "print(f\"üìÇ Nous avons d√©ja {len(url_deja_scrape)} URLs sont dans le dataset Fragrantica.\")\n",
    "print(\"--------------------------------------------------------------------------------\")\n",
    "\n",
    "num_url_scrap = 0\n",
    "#2) It√©rer sur les batches \n",
    "for i in range(num_batches):\n",
    "    print(f\"\\nüì° Traitement du batch {i+1}/{num_batches}...\")\n",
    "\n",
    "    batch = df_a_scraper.iloc[i * batch_size : (i + 1) * batch_size]\n",
    "    liste_url = batch[\"Lien du Parfum\"].tolist()\n",
    "\n",
    "    # üîç Supprimer les URLs d√©j√† scrap√©es\n",
    "    old_len = len(liste_url)\n",
    "    liste_url = [url for url in liste_url if url not in url_deja_scrape]\n",
    "    new_len = len(liste_url)\n",
    "    print(f\"üîç {old_len - new_len} URLs sur {old_len} ont d√©j√† √©t√© scrap√©es et retir√©es du batch {i+1}.\")\n",
    "\n",
    "    if not liste_url:  # Si aucun URL √† scraper, passer au batch suivant\n",
    "        print(f\"‚è≠Ô∏è Batch {i+1} ignor√© (toutes les URLs √©taient d√©j√† scrap√©es).\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        scraped_data = sip.scraping_multi_perfume_info(liste_url)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"‚è±Ô∏è Temps d'ex√©cution du scraping sur le batch{i+1} : {execution_time:.1f} secondes.\")\n",
    "        print(f\"‚è±Ô∏è Soit un total de {execution_time/len(liste_url):.1f} secondes par URL.\")\n",
    "        \n",
    "        # V√©rifier si le batch est vide\n",
    "\n",
    "        '''\n",
    "        cette condition n'est jamais remplie\n",
    "        '''\n",
    "        if scraped_data['nom_parfum'].empty:\n",
    "            print(f\"üö® Erreur critique : Le batch {i+1} est vide. On fait une grosse pause\")\n",
    "            time.sleep(3600)  # Pause de 5 minutes pour √©viter d'√™tre bloqu√© par le site\n",
    "            continue\n",
    "        # V√©rifier si le scrappinng c'es mal pass√©\n",
    "        if scraped_data['nom_parfum'].isnull().sum() > 0:\n",
    "            print(f\"üö® Erreur critique : Le batch {i+1} contient {scraped_data['nom_parfum'].isnull().sum()} lignes vides. On fait une grosse pause\")\n",
    "            # Filtrer les lignes valides\n",
    "            scraped_data = scraped_data.dropna(subset=['nom_parfum'])\n",
    "    \n",
    "            file_name = f\"scrap_batch_{i+1}.csv\"\n",
    "            scraped_data.to_csv(file_name, index=False) # Sauvegarde du batch sans index inutile\n",
    "            print(f\"‚úÖ Batch {i+1} enregistr√© dans {file_name} avec les lignes valides.\")\n",
    "            num_url_scrap += len(scraped_data)\n",
    "            time.sleep(3600)  # Pause de 5 minutes pour √©viter d'√™tre bloqu√© par le site\n",
    "            continue\n",
    "            '''        \n",
    "            print(f\"üö® Erreur critique : Le batch {i+1} contient des lignes vides. Arr√™t imm√©diat du script.\")\n",
    "            sys.exit(1)  # üíÄ Arr√™t imm√©diat du script avec un code d'erreur 1\n",
    "            '''\n",
    "\n",
    "        else:\n",
    "            file_name = f\"scrap_batch_{i+1}.csv\"\n",
    "            scraped_data.to_csv(file_name, index=False) # Sauvegarde du batch sans index inutile\n",
    "            print(f\"‚úÖ Batch {i+1} enregistr√© dans {file_name}.\")\n",
    "            num_url_scrap += new_len\n",
    "\n",
    "        print(\"On attend 30 minutes\")\n",
    "        time.sleep(1801)  # Pause pour √©viter d'√™tre bloqu√© par le site\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur lors du scraping du batch {i+1}: {e}\")\n",
    "\n",
    "'''\n",
    "Fais une grosse pause seulement si on a une 'Too many requests' erreur\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "print(f\"\\nüéâ AU FINAL {num_url_scrap} URLs ont √©t√© scrap√©es avec succ√®s !\")\n",
    "\n",
    "#3) Regarder le dernier batch\n",
    "scraped_data = pd.DataFrame()\n",
    "scraped_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code pour ajouter nos nouvelles lignes √† 'Fragrantica_dataset.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Les donn√©es du batch 18 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 19 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 20 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 21 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 22 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 23 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 24 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 25 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 26 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 27 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 28 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 29 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 30 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 31 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 32 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n",
      "‚úÖ Les donn√©es du batch 33 ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\n"
     ]
    }
   ],
   "source": [
    "num_premier_batch = 1\n",
    "num_dernier_batch = 2\n",
    "for i in range(num_premier_batch-1, num_dernier_batch):\n",
    "    scraped_data = pd.read_csv(f\"scrap_batch_{i+1}.csv\")\n",
    "    Fragrantica_dataset = pd.read_csv(\"Fragrantica_dataset.csv\")\n",
    "\n",
    "    # Concat√©ner les deux DataFrames\n",
    "    combined_data = pd.concat([Fragrantica_dataset, scraped_data])\n",
    "\n",
    "    # Supprimer les doublons\n",
    "    combined_data.drop_duplicates(subset=['url'], inplace=True)\n",
    "\n",
    "    # Sauvegarder le dataset combin√©\n",
    "    combined_data.to_csv(\"Fragrantica_dataset.csv\", index=False)\n",
    "    print(f\"‚úÖ Les donn√©es du batch {i+1} ont √©t√© ajout√©es √† Fragrantica_dataset.csv sans doublons.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
